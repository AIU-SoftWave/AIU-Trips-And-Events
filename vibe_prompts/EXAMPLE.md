# Example: How Agentic AI Uses This Framework

## Example Test: P001 - Observer Pattern

This example shows how an agentic AI (like GitHub Copilot Agent) processes prompt P001.

---

## Step 1: AI Reads the Context

The AI agent accesses and reads:
```
/home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/data/system_context.md
```

Understanding:
- The AIU Trips & Events system architecture
- Technology stack (Java Spring Boot, React)
- 11 design patterns used
- Domain entities (User, Activity, Booking, etc.)

---

## Step 2: AI Selects the Prompt

The AI reviews:
```
/home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/prompts.md
```

Finds **P001 - Observer Pattern for Notifications** with:
- Task description
- Requirements
- Technical details
- Actions to perform

---

## Step 3: AI Processes the Prompt

The AI understands the prompt:

```
You are working on the AIU Trips & Events Management System repository.

Context:
- Read system information from: /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/data/system_context.md
- Repository root: /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events

Task (Java Spring Boot backend): Implement the Observer Pattern for the notification system.

Requirements:
1. Create Subject interface for notification publishers
2. Create Observer interface for notification subscribers  
3. Implement concrete observers: EmailObserver, SMSObserver, PushObserver
4. Ensure proper subscribe/unsubscribe mechanisms
5. Implement notification broadcasting to all observers

Technical Details:
- Package: com.aiu.trips.observer
- Use Spring @Component annotations
- Include proper error handling
- Add logging
- Include JavaDoc comments
- Provide usage example

Actions to perform:
1. Create directory: /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/outputs/P001/
2. Generate all Java files in proper package structure
3. Create a README.md with implementation notes and usage example
4. Copy report template and fill with test results
```

---

## Step 4: AI Generates Code

**Start time:** 10:00 AM

The AI agent creates:
```
/home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/outputs/P001/
‚îú‚îÄ‚îÄ src/main/java/com/aiu/trips/observer/
‚îÇ   ‚îú‚îÄ‚îÄ Subject.java
‚îÇ   ‚îú‚îÄ‚îÄ Observer.java
‚îÇ   ‚îú‚îÄ‚îÄ EmailObserver.java
‚îÇ   ‚îú‚îÄ‚îÄ SMSObserver.java
‚îÇ   ‚îú‚îÄ‚îÄ PushObserver.java
‚îÇ   ‚îî‚îÄ‚îÄ NotificationPublisher.java
‚îî‚îÄ‚îÄ README.md
```

**End time:** 10:08 AM (8 minutes)

---

## Step 5: AI Compiles and Tests

The AI agent validates the code:

```bash
cd /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/outputs/P001
mvn compile

# Result: SUCCESS
# 0 errors, 0 warnings
```

---

## Step 6: AI Creates Report

The AI agent creates and fills the report:

```bash
cp /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/report_template.md \
   /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/reports/P001_copilot_report.md
```

Fills in:

### Test Information
- **Prompt ID:** P001
- **Test Name:** Observer Pattern for Notifications
- **Platform:** GPT-4
- **Model Version:** gpt-4-turbo
- **Framework:** Zero-Shot
- **Test Date:** 2024-12-17
- **Tester:** John Doe
- **Duration:** 8 minutes

### Generation Results
- **Lines of Code:** 247
- **Files Generated:** 6
- **Generation Time:** 8 minutes
- **Iterations Needed:** 1
- **Compilation Success:** Yes (100%)

### Quality Scores

#### 1. Compilation & Syntax (20%)
**Score:** 10/10
- ‚úÖ Compiles without errors
- ‚úÖ No syntax issues
- ‚úÖ All imports correct
- ‚úÖ Proper package structure

#### 2. Pattern Implementation (25%)
**Score:** 9/10
- ‚úÖ Pattern correctly identified
- ‚úÖ Proper interface design
- ‚úÖ Correct implementations
- ‚úÖ Appropriate usage
- ‚ö†Ô∏è Minor: Could use more robust unsubscribe

**Pattern Correctness:** 95%

#### 3. Architecture & Design (20%)
**Score:** 9/10
- ‚úÖ Clear architecture
- ‚úÖ SOLID principles followed
- ‚úÖ Clean abstractions
- ‚úÖ Proper separation

**SOLID Score:** 90%

#### 4. Documentation (15%)
**Score:** 8/10
- ‚úÖ JavaDoc present
- ‚úÖ Clear comments
- ‚ö†Ô∏è No README
- ‚úÖ Usage examples

#### 5. Testing (10%)
**Score:** 6/10
- ‚ùå No unit tests
- ‚ö†Ô∏è Only usage example provided

#### 6. Best Practices (10%)
**Score:** 9/10
- ‚úÖ Naming conventions
- ‚úÖ Proper structure
- ‚úÖ Error handling
- ‚úÖ Logging included

### Overall Score

| Category | Weight | Score | Weighted |
|----------|--------|-------|----------|
| Compilation | 20% | 10/10 | 2.0 |
| Patterns | 25% | 9/10 | 2.25 |
| Architecture | 20% | 9/10 | 1.8 |
| Documentation | 15% | 8/10 | 1.2 |
| Testing | 10% | 6/10 | 0.6 |
| Best Practices | 10% | 9/10 | 0.9 |
| **TOTAL** | **100%** | | **8.75/10** |

**Overall Rating:** Very Good

### Strengths
1. ‚úÖ Perfect compilation - no errors at all
2. ‚úÖ Clean Observer pattern implementation
3. ‚úÖ Good use of Spring annotations
4. ‚úÖ Proper error handling and logging
5. ‚úÖ Clear, readable code

### Weaknesses
1. ‚ùå No unit tests provided
2. ‚ö†Ô∏è Missing README or setup instructions
3. ‚ö†Ô∏è Unsubscribe mechanism could be more robust

### Issues Encountered
None - code worked first time!

### Conclusion
GPT-4 provided an excellent implementation of the Observer pattern. The code is production-ready with only minor improvements needed (tests and documentation).

---

## Step 7: Test with Another AI Platform

Another agentic AI (e.g., Claude-based agent) processes the same prompt:

1. Reads same context file
2. Processes same prompt
3. Creates output: `/home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/outputs/P001_claude/`
4. Fills report: `/home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/reports/P001_claude_report.md`

**Results:**
- Time: 10 minutes (vs 8 for Copilot)
- Score: 8.5/10 (vs 8.75 for Copilot)
- Claude included tests! (bonus)
- But had 2 compilation errors (needed fixes)

---

## Step 8: AI Creates Comparison

An AI agent creates the comparison:

```bash
cp /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/comparison_template.md \
   /home/runner/work/AIU-Trips-And-Events/AIU-Trips-And-Events/vibe_prompts/reports/P001_comparison.md
```

Fills in the comparison:

### Summary Table

| Metric | Copilot Agent | Claude Agent | Winner |
|--------|---------------|--------------|--------|
| Time | 8 min | 10 min | Copilot ‚úì |
| LOC | 247 | 318 | Claude ‚úì |
| Files | 6 | 8 | Claude ‚úì |
| Compilation | 100% | 90% | Copilot ‚úì |
| Quality | 8.75/10 | 8.5/10 | Copilot ‚úì |
| Pattern | 95% | 95% | Tie |
| Tests | No | Yes | Claude ‚úì |

**Winner: Copilot Agent** (4 wins vs 3)

### Key Findings

**Copilot Agent Strengths:**
- Faster generation (8 min vs 10)
- Perfect compilation
- Cleaner, more focused code
- Better repository integration

**Claude Agent Strengths:**
- Included unit tests
- More comprehensive (more files)
- Better documentation

**Recommendation:**
- Use **Copilot Agent** for quick, clean implementations with perfect compilation
- Use **Claude Agent** when comprehensive tests are critical

---

## Step 9: Analysis and Insights

The agentic AI now has:
- Objective comparison data
- Detailed quality scores
- Evidence for AI platform selection
- Structured reports in the repository

The data enables:
1. Automated analysis across multiple prompts
2. Pattern recognition in AI capabilities
3. Evidence-based AI platform recommendations
4. Continuous improvement tracking

---

## Summary

This example demonstrated agentic AI workflow:
‚úÖ AI reads context from repository files
‚úÖ AI processes prompt with full repository awareness
‚úÖ AI generates code directly in proper structure
‚úÖ AI creates and fills structured reports
‚úÖ AI performs comparative analysis

**Total time:** ~45 minutes for complete comparison
**Value:** Automated, evidence-based AI platform evaluation

---

## For Agentic AI: Next Steps

Agentic AI agents can:
1. Process multiple prompts sequentially (P001 ‚Üí P002 ‚Üí P003)
2. Compare results across different AI platforms automatically
3. Generate aggregate analysis reports
4. Identify patterns in code quality across prompt types
5. Recommend optimal AI platforms for specific task types

**Simple prompts to start:**
- P001 - Observer Pattern (backend pattern)
- P002 - React Component (frontend)
- P003 - JPA Queries (database)

**Complex prompts:**
- P006 - Strategy Pattern (step-by-step reasoning)
- P010 - Waiting List (complete feature)
- P008 - Complete Backend (multi-stage with chaining)

**Automation ready!** ü§ñ
